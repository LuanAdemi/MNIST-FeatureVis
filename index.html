<!doctype html>

<head>
    <title>Understanding MNIST-Classifier</title>
    <script src="scripts/template.v2.js"></script>
    <script src="scripts/script.js"></script>
    <script type="module" src="https://unpkg.com/ionicons@4.5.10-0/dist/ionicons/ionicons.esm.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf8">
    <link rel="stylesheet" href="style/style.css">
</head>

<body>
<d-front-matter>
    <script id='distill-front-matter' type="text/json">{
          "title": "Understanding MNIST-Classifiers",
          "description": "Using Feature Visualization to explore and understand the inner workings of a MNIST-Classifier.",
          "published": "February 22, 2022",
          "authors": [
            {
              "author":"Luan Ademi",
              "authorURL":"https://github.com/LuanAdemi",
              "affiliations": [{"name": "Karlsruhe Institute of Technology", "url": "https://kit.edu/english"}]
            }
          ],
          "katex": {
            "delimiters": [
              {"left": "$$", "right": "$$", "display": false}
            ]
          }
        }
    </script>
</d-front-matter>
<header><img src="assets/GitHub-Mark-Light-64px.png" style="width: 40px;" alt="GitHub"></header>
<d-title style="background-color:#3A3D45;color: white;"></d-title>

<d-byline style="background-color: #F5F5F5;"></d-byline>
<div class="hero-div base-grid">
    <figure class="hero" style="grid-column: middle;margin-top: 32px;">
        <img src="assets/hero.png" alt="" draggable="false">
        <figcaption>
            Main detector circuits and their activation maps for
            three primitive detectors of a mnist
            <d-cite bibtex-key="mnist"></d-cite>
            classifier for each class of
            digit ranging from 0 to 9. See <a href="#section-3">section 3</a> for an in-depth explanation.
        </figcaption>
    </figure>

</div>
<d-article>

    <a class="marker" href="#section-1" id="section-1"><span>1</span></a>
    <h2>Introduction</h2>
    <p>In the recent years, a lot of research has been done in the field of interpretability,
        providing us with powerful tools to help us to understand our models. Methods like GradCam
        <d-cite
                bibtex-key="gradcam"></d-cite>
        enabled researchers to get a hint at what image models were looking for
        to make their prediction.
    </p>
    <p>Understanding the inner workings of our models is not only a research interest, but also provides a baseline
        for developing safe AI for a broader use and maybe even extract knowledge
        <d-cite bibtex-key="elk"></d-cite>
        .
    </p>
    <p>This article focuses on circuit based interpretability
        <d-cite bibtex-key="cammarata2020thread"></d-cite>
        ,
        which is a new way of looking at atomic structures in neural networks. We will use the methods developed by
        this field to gain useful insights on how a classifier model classifies
        handwritten digits.
    </p>
    <p>It is also intended to act as a boilerplate for everyone trying to understand their
        models or needing a head start in the field of circuit based interpretability.</p>
    <a class="marker" href="#section-2" id="section-2"><span>2</span></a>
    <h2>Classification</h2>
    <p>Let's begin by looking at the model and the task we are going to inspect in this article.</p>
    <p>We are going to train ourself a</p>

    <a class="marker" href="#section-3" id="section-3"><span>3</span></a>
    <h2>Circuit based interpretability</h2>
    <p>A circuit is a combination of primitive feature detectors, that enables a neural network to detect essential
        features of its input.</p>
    <a class="marker" href="#section-3-1" id="section-3-1"><span>3.1</span></a>
    <h3>Feature Visualization
        <d-cite bibtex-key="olah2017feature"></d-cite>
    </h3>
    <div class="graphic">
        <figure class="image-grid">
            <div class="grid-image">
                <figure>
                    <img src="assets/0.png" alt="" draggable="false">
                </figure>
            </div>
            <div class="grid-image">
                <figure><img src="assets/1.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image">
                <figure><img src="assets/2.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image">
                <figure><img src="assets/3.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image">
                <figure><img src="assets/4.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image">
                <figure><img src="assets/5.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image small-hidden">
                <figure><img src="assets/6.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image small-hidden">
                <figure><img src="assets/7.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image small-hidden">
                <figure><img src="assets/8.png" alt="" draggable="false"></figure>
            </div>
            <div class="grid-image small-hidden">
                <figure><img src="assets/9.png" alt="" draggable="false"></figure>
            </div>
        </figure>
        <figcaption>Feature Visualization of the last layer before a
            softmax activation for each class. This shows us the combination of primitive detector circuits used by
            the model to classify handwritten digits
            <d-cite bibtex-key="mnist"></d-cite>
            .
            The detailed model specifications and a visualization for every channel can be found in the <a
                    href="#appendix">appendix</a>.
        </figcaption>
    </div>

    <p>Using Feature Visualization, we are able to understand visually what certain part of our model strongly react
        to. Through optimizing the activation of certain neurons, channels, regions or whole layers, we are able to
        generate an input for our model, that shows us what excites the inspected part of our model the most.</p>
    <aside>See <a href="https://distill.pub/2018/building-blocks/">this article</a> for some more complex activation
        objectives and their use-cases. This section is more or less an overview of the distill series for circuits
        <d-cite bibtex-key="cammarata2020thread"></d-cite>
        .<br><br></aside>
    <p>In general there are five main types of feature visualizations:</p>
    <div class="feature-types">
        <p>
            <d-figure><img src="assets/neuron_activation.png" alt="" style="float: left;padding-bottom: 20px;"
                           draggable="false"></d-figure>
            <b>Neuron activation</b> can be used as an optimization objective to
        </p>
        <p>
            <d-figure><img src="assets/channel_activation.png" alt="" style="float: left;padding-bottom: 20px;"
                           draggable="false"></d-figure>
            <b>Channel activation</b> can be used as an optimization objective to
        </p>
        <p>
            <d-figure><img src="assets/layer_activation.png" alt="" style="float: left;padding-bottom: 23px;"
                           draggable="false"></d-figure>
            <b>Layer activation</b> can be used as an optimization objective to
        </p>
        <p>
            <d-figure><img src="assets/pre-softmax-activation.png" alt="" style="float: left;padding-bottom: 28px;"
                           draggable="false"></d-figure>
            <b>Pre-Softmax activation</b> can be used as an optimization objective to
        </p>
        <p>
            <d-figure><img src="assets/post-softmax-activation.png" alt="" style="float: left;padding-bottom: 28px;"
                           draggable="false"></d-figure>
            <b>Post-Softmax activation</b> can be used as an optimization objective to
        </p>
    </div>
    <p>These objectives are the building blocks for complex analyses of our models. We can perform joint optimizations
        by combining different objectives for the optimization step.</p>

    <d-code block language="python">
        activation = {} # dictionary to store the activation of a layer

        def create_hook(name):
            def hook(m, i, o):
                # copy the output of the given layer
                activation[name] = o

            return hook

            model.fc2.register_forward_hook(create_hook("fc2"))
    </d-code>

    <d-code block language="python">
        class Objective:
            def __init__(self, model, layer):
                self.activation = {}
                self.model = model

            def add_forward_hook(self, layer, name):
                def create_hook(name):
                    def hook(m, i, o):
                    # copy the output of the given layer
                    self.activation[name] = o.unsqueeze(0)

                return hook

                self.model[layer].register_forward_hook(create_hook(name))

            def __call__(self, name):
                return NotImplementedError

    </d-code>

    <d-code block language="python">
        class neuron_objective(Objective):
            def __call__(self, name, channel, neuron):
                return -self.activation[name][channel, neuron].mean()

    </d-code>
    <d-code block language="python">
        class channel_objective(Objective):
            def __call__(self, name, channel):
                return -self.activation[name][channel, :].mean()

    </d-code>
    <d-code block language="python">
        class layer_objective(Objective):
            def __call__(self, name):
                return -self.activation[name][:, :].mean()

    </d-code>
    <a class="marker" href="#section-3-2" id="section-3-2"><span>3.2</span></a>
    <h3>Circuits</h3>
    <div class="figure-div base-grid">

        <ion-icon name="hand" class="interactive-icon">
        </ion-icon>


        <figure class="class-picker-figure">
            <div class="class-picker">
                <a id="picker-1" onclick="setActivePicker(1)" class="picker-class active"><img
                        src="assets/samples/0_2.png" draggable="false" alt=""></a>
                <a id="picker-2" onclick="setActivePicker(2)" class="picker-class"><img src="assets/samples/1_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-3" onclick="setActivePicker(3)" class="picker-class"><img src="assets/samples/2_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-4" onclick="setActivePicker(4)" class="picker-class"><img src="assets/samples/3_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-5" onclick="setActivePicker(5)" class="picker-class"><img src="assets/samples/4_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-6" onclick="setActivePicker(6)" class="picker-class"><img src="assets/samples/5_1.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-7" onclick="setActivePicker(7)" class="picker-class"><img src="assets/samples/6_1.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-8" onclick="setActivePicker(8)" class="picker-class"><img src="assets/samples/7_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-9" onclick="setActivePicker(9)" class="picker-class"><img src="assets/samples/9_0.png"
                                                                                        draggable="false" alt=""></a>
                <a id="picker-10" onclick="setActivePicker(10)" class="picker-class"><img
                        src="assets/samples/9_0.png" draggable="false" alt=""></a>
            </div>
            <d-figure id="circuit" class="circuit">
                <img id="circuit-image" src="assets/circuits/Circuit0.png" alt="" draggable="false">
            </d-figure>
        </figure>
    </div>
</d-article>

<d-appendix>

    <h3>Reviewers</h3>
    <p>Some text with links describing who reviewed the article.</p>

    <d-bibliography>
        <script type="text/bibtex">
                @article{olah2017feature,
                    author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
                    title = {Feature Visualization},
                    journal = {Distill},
                    year = {2017},
                    note = {https://distill.pub/2017/feature-visualization},
                    doi = {10.23915/distill.00007},
                    url = {https://distill.pub/2017/feature-visualization/}
                  },
                  @online{mnist, 
                    author = {LeCun, Yann and Cortes, Corinna and J.C. Burges, Christopher},
                    title = {The MNIST Database},
                    year = 1998,
                    url = {http://yann.lecun.com/exdb/mnist/ },
                },
                @article{cammarata2020thread,
                    author = {Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris and Petrov, Michael and Schubert, Ludwig and Voss, Chelsea and Egan, Ben and Lim, Swee Kiat},
                    title = {Thread: Circuits},
                    journal = {Distill},
                    year = {2020},
                    note = {https://distill.pub/2020/circuits},
                    doi = {10.23915/distill.00024},
                    url = {https://distill.pub/2020/circuits/}
                  },
                @article{gradcam,
                    author    = {Ramprasaath R. Selvaraju and
                                 Abhishek Das and
                                 Ramakrishna Vedantam and
                                 Michael Cogswell and
                                 Devi Parikh and
                                 Dhruv Batra},
                    title     = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
                                 via Gradient-based Localization},
                    journal   = {CoRR},
                    volume    = {abs/1610.02391},
                    year      = {2016},
                    url       = {http://arxiv.org/abs/1610.02391},
                    eprinttype = {arXiv},
                    eprint    = {1610.02391},
                    timestamp = {Mon, 13 Aug 2018 16:46:58 +0200},
                    biburl    = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
                    bibsource = {dblp computer science bibliography, https://dblp.org}
                },
                @article{elk,
                    author = {Christiano, Paul and Cotra, Ajeya and Xu, Mark},
                    title  = {Eliciting latent knowledge: How to tell if your eyes deceive you},
                    year   = {2021},
                    url    = {https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit}
                }

        </script>
    </d-bibliography>
</d-appendix>
</body>